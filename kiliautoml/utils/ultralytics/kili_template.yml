# YOLOv5 🚀 by Ultralytics, GPL-3.0 license
# Kili project dataset https://cloud.kili-technology.com/label/projects/ckysuic0y0ldc0lvoeltld164/menu/analytics
# Before running, make sure that the KILI_API_KEY environment variable is set with the API key obtained from Kili
# (in https://cloud.kili-technology.com/label/my-account/api-key if you are using the cloud version)
#
# Example usage: python train.py --data kili.yaml
# parent
# ├── yolov5
# └── datasets
#     └── kili  ← downloads here
#

# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: {{ data_path }} # ../datasets/kili/<YOUR_KILI_PROJECT_ID> # dataset root dir with your Kili project ID
train: images/train # train images (relative to 'path')
val: images/val # val images (relative to 'path')
test: images/test # test images (optional)

# Classes
names: [{% for class_name in class_names %}"{{ class_name }}", {% endfor %}] # class names, must match your Kili project class names.
nc: {{ number_classes }} # number of classes (cardinality of the list above)

# The proportions of he training and validation dataset, the sum should be < 1.0. The remainder is used as the test set.
train_val_proportions:
  - 0.8
  - 0.1

# Download script/URL (optional)
download: |
  import math
  import os
  import re
  import time
  from kili.client import Kili
  import requests
  from tqdm.auto import tqdm
  print("Downloading datasets from Kili")
  train_val_proportions = yaml['train_val_proportions']
  path = yaml.get('path', '')
  if '/kili/' not in path:
      raise ValueError("'path' field in config must contain '/kili/'")
  project_id = "{{ project_id }}"
  kili = Kili(api_key="{{ kili_api_key }}")
  total ={% if max_assets is not none %} min({{ max_assets }}, kili.count_assets(project_id=project_id)) {% else %} kili.count_assets(project_id=project_id) {% endif %}
  if total == 0:
      raise Exception("No asset in project. Exiting...")
  first = 100
  assets = []
  for skip in tqdm(range(0, total, first)):
      assets += kili.assets(
          project_id=project_id,
          first=first,
          skip=skip,
          disable_tqdm=True,
          status_in =  {{ asset_status_in }},
          fields=[
              'id',
              'content',
              'labels.createdAt',
              'labels.jsonResponse',
              'labels.labelType'])
  n_train_assets = math.floor(len(assets) * train_val_proportions[0])
  n_val_assets = math.floor(len(assets) * train_val_proportions[1])
  assets_splits = {
      "train": assets[:n_train_assets],
      "val": assets[n_train_assets : n_train_assets + n_val_assets],
      "test": assets[n_train_assets + n_val_assets :],
  }

  for name_split, assets_split in assets_splits.items():
      if len(assets_split) == 0:
          raise Exception("No asset in dataset, exiting...")
      path_split = os.path.join(path, yaml.get(name_split, ''))
      print(f"Building {name_split} in {path_split} ...")
      os.makedirs(path_split, exist_ok=True)
      for asset in tqdm(assets_split):
          tic = time.time()
          n_try = 0
          img_data = None
          while n_try < 20:
              try:
                  img_data = requests.get(asset['content'], headers={
                    'Authorization': 'X-API-Key: {{ kili_api_key }}',
                    'PROJECT_ID': project_id,
                  }).content
                  break
              except Exception:
                  time.sleep(1)
                  n_try += 1
          if img_data is None:
              asset_id = asset["id"]
              raise Exception(f"Failed to get image data for asset {asset_id}")
          with open(os.path.join(path_split, asset['id'] + '.jpg'), 'wb') as handler:
              handler.write(img_data)
          toc = time.time() - tic
          throttling_per_call = 60.0 / 250 # Kili API calls are limited to 250 per minute
          if toc < throttling_per_call:
              time.sleep(throttling_per_call - toc)

      names = yaml.get('names', [])
      path_labels = re.sub('/images/', '/labels/', path_split)
      print(path_labels)
      os.makedirs(path_labels, exist_ok=True)
      for asset in assets_split:
          with open(os.path.join(path_labels, asset['id'] + '.txt'), 'w') as handler:
              json_response = asset['labels'][0]['jsonResponse']
              for job in json_response.values():
                  for annotation in job.get('annotations', []):
                      name = annotation['categories'][0]['name']
                      try:
                          category = names.index(name)
                      except ValueError:
                          pass
                      bounding_poly = annotation.get('boundingPoly', [])
                      if len(bounding_poly) < 1:
                          continue
                      if 'normalizedVertices' not in bounding_poly[0]:
                          continue
                      normalized_vertices = bounding_poly[0]['normalizedVertices']
                      x_s = [vertice['x'] for vertice in normalized_vertices]
                      y_s = [vertice['y'] for vertice in normalized_vertices]
                      x_min, y_min = min(x_s), min(y_s)
                      x_max, y_max = max(x_s), max(y_s)
                      _x_, _y_ = (x_max + x_min) / 2, (y_max + y_min) / 2
                      _w_, _h_ = x_max - x_min, y_max - y_min
                      handler.write(f'{category} {_x_} {_y_} {_w_} {_h_}\n')
