{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpns4q3djVfA"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kili-technology/automl/blob/main/notebooks/semantic_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfLtCTikga87"
      },
      "source": [
        "In this notebook, we will see how we can simply create a segmentation model with AutoML to pre-annotate our dataset on the Kili Platform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvxGxVPugYzh"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "API_KEY=getpass(\"Enter your KILI API key: \")\n",
        "%env KILI_API_KEY=$API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ2TJpRF33L9"
      },
      "source": [
        "# Installation AutoML (5min)\n",
        "\n",
        "We first follow the install procedure explained in the README.md."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9s66MZanYrTT"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/kili-technology/automl.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdsEnP8OhEhU"
      },
      "outputs": [],
      "source": [
        "%cd automl\n",
        "!git submodule update --init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDlr2E3Vg-_9"
      },
      "outputs": [],
      "source": [
        "# %pip install torch\n",
        "%pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XlwJf3RyQ1G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"PYTHONPATH\"] += \":/content/automl/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0AcxQyPeRFJ"
      },
      "outputs": [],
      "source": [
        "KILI_URL=\"https://cloud.kili-technology.com/\"\n",
        "\n",
        "os.environ['api_endpoint'] =f'{KILI_URL}api/label/v2/graphql'\n",
        "api_endpoint = os.environ['api_endpoint']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5uPJHsHqALr"
      },
      "outputs": [],
      "source": [
        "USE_DRIVE=False\n",
        "if USE_DRIVE:\n",
        "  from google.colab import drive\n",
        "  drive.mount(\"/content/drive\")\n",
        "\n",
        "  os.environ['KILIAUTOML_CACHE'] =\"/content/drive/automl\"\n",
        "else:\n",
        "  os.environ['KILIAUTOML_CACHE'] = os.path.join(os.environ['HOME'], \".cache\", \"kili\", \"automl\")\n",
        "\n",
        "KILIAUTOML_CACHE = os.environ['KILIAUTOML_CACHE']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZovAasEognJE"
      },
      "source": [
        "# Setup Mock Coco Project\n",
        "\n",
        "Here we download a dataset in the coco format and we convert it to the kili format before uploading it to Kili"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4UNHF1Bgqw6"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/kili-machine-learning-automl/notebooks/coco_dataset_2017_val.zip\n",
        "!unzip -q coco_dataset_2017_val.zip \n",
        "dataset_dir = \"./coco_dataset\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51Mun7aFMlQA"
      },
      "source": [
        "#### Convert coco format to kili format\n",
        "Then we use the kili format to create a new projet containing those coco images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty32kGXLFUV8"
      },
      "outputs": [],
      "source": [
        "LIMIT = 200 # nb of images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nXBT3TpgsxX"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List\n",
        "import numpy as np\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "from typing_extensions import Literal, TypedDict\n",
        "\n",
        "class CategoryT(TypedDict):\n",
        "    name: str\n",
        "    confidence: int  # between 0 and 100\n",
        "\n",
        "# ## DETECTRON FORMAT\n",
        "\n",
        "class ImageCoco(TypedDict):\n",
        "    id: int\n",
        "    license: int\n",
        "    file_name: str\n",
        "    height: int\n",
        "    width: int\n",
        "    date_captured: None\n",
        "\n",
        "\n",
        "class CategoryCoco(TypedDict):\n",
        "    id: int\n",
        "    name: str\n",
        "    supercategory: str\n",
        "\n",
        "\n",
        "class AnnotationsCoco(TypedDict):\n",
        "    id: int\n",
        "    image_id: int  # -> external_id : the last part of the url\n",
        "    category_id: int\n",
        "    bbox: List[int]\n",
        "    segmentation: List[List[float]]  # [[x, y, x, y, x ...]]\n",
        "    area: int\n",
        "    iscrowd: int\n",
        "\n",
        "\n",
        "class CocoFormat(TypedDict):\n",
        "    info: Dict  # type: ignore\n",
        "    licenses: List[Dict]  # type: ignore\n",
        "    categories: List[CategoryCoco]\n",
        "    images: List[ImageCoco]\n",
        "    annotations: List[AnnotationsCoco]\n",
        "\n",
        "\n",
        "# ## KILI Polygon Semantic Format\n",
        "\n",
        "class NormalizedVertice(TypedDict):\n",
        "    x: float\n",
        "    y: float\n",
        "\n",
        "\n",
        "class NormalizedVertices(TypedDict):\n",
        "    normalizedVertices: List[NormalizedVertice]\n",
        "\n",
        "\n",
        "class SemanticAnnotation(TypedDict):\n",
        "    boundingPoly: List[NormalizedVertices]  # len(self.boundingPoly) == 1\n",
        "    mid: str\n",
        "    type: Literal[\"semantic\"]\n",
        "    categories: List[CategoryT]\n",
        "\n",
        "\n",
        "class SemanticJob(TypedDict):\n",
        "    annotations: List[SemanticAnnotation]\n",
        "\n",
        "\n",
        "job_name = \"SEMANTIC_JOB\"\n",
        "\n",
        "\n",
        "def camelCase(st):\n",
        "    return st.capitalize().replace(\" \", \"_\")\n",
        "\n",
        "def convert_coco_to_kili(coco_format: CocoFormat) -> Dict[str, SemanticJob]:\n",
        "    \"\"\"\n",
        "    Coco format:\n",
        "    <dataset_dir>/\n",
        "        data/\n",
        "            <filename0>.<ext>\n",
        "            <filename1>.<ext>\n",
        "            ...\n",
        "        labels.json\n",
        "\n",
        "    We convert the json to kili format.\n",
        "    \"\"\"\n",
        "    mapping_external_id_to_semanticjob: Dict[str, SemanticJob] = {}\n",
        "\n",
        "    print(\"Nb categories\", len(coco_format[\"categories\"]))\n",
        "    print(\"Nb annotations\", len(coco_format[\"annotations\"]))\n",
        "    print(\"Nb images\", len(coco_format[\"images\"]))\n",
        "\n",
        "    for coco_annotation in tqdm(coco_format[\"annotations\"], desc=\"Extracting COCO Objects\"):\n",
        "        # Extract Coco info\n",
        "        category_names = [\n",
        "            cat[\"name\"] for cat in coco_format[\"categories\"] if cat[\"id\"] == coco_annotation[\"category_id\"]\n",
        "        ]\n",
        "        assert len(category_names) == 1\n",
        "        category_name = category_names[0]\n",
        "        category_kili_id = camelCase(category_name)\n",
        "\n",
        "        image_names = [\n",
        "            image\n",
        "            for image in coco_format[\"images\"]\n",
        "            if image[\"id\"] == coco_annotation[\"image_id\"]\n",
        "        ]\n",
        "        assert len(image_names) == 1\n",
        "        external_id = image_names[0][\"file_name\"]\n",
        "        height, width = image_names[0][\"height\"], image_names[0][\"width\"]\n",
        "\n",
        "        # convert to Kili\n",
        "        # Each connected component becones a new object in Kili format\n",
        "        connected_components  : List[SemanticAnnotation]= []\n",
        "        for single_connected_component in coco_annotation[\"segmentation\"]:\n",
        "            tab_xy = single_connected_component  # We take only the first connected component\n",
        "            if type(tab_xy) != list:\n",
        "                # print(single_connected_component)\n",
        "                continue\n",
        "            tab_x = list(np.array(tab_xy[::2]) / width )\n",
        "            tab_y = list(np.array(tab_xy[1::2]) / height )\n",
        "\n",
        "            normalizedVertices: NormalizedVertices = {\n",
        "                \"normalizedVertices\": [NormalizedVertice(x=x, y=y) for x, y in zip(tab_x, tab_y)]\n",
        "            }\n",
        "            boundingPoly = [normalizedVertices]\n",
        "            categories = [CategoryT(name=category_kili_id, confidence=100)]\n",
        "\n",
        "            annotation_kili = SemanticAnnotation(\n",
        "                boundingPoly=boundingPoly,\n",
        "                mid=None,# type:ignore  # Created on the fly\n",
        "                type=\"semantic\",\n",
        "                categories=categories,\n",
        "            )\n",
        "            connected_components.append(annotation_kili)\n",
        "        if external_id not in mapping_external_id_to_semanticjob:\n",
        "            mapping_external_id_to_semanticjob[external_id] = SemanticJob(annotations=connected_components)\n",
        "        else:\n",
        "            previous_annotatations = mapping_external_id_to_semanticjob[external_id][\"annotations\"]\n",
        "            mapping_external_id_to_semanticjob[external_id] = SemanticJob(annotations=previous_annotatations + connected_components)\n",
        "\n",
        "    return mapping_external_id_to_semanticjob\n",
        "\n",
        "\n",
        "def convert_coco_to_kili_json_interface(coco_format: CocoFormat):\n",
        "    \"\"\"\n",
        "    Coco format:\n",
        "    <dataset_dir>/\n",
        "        data/\n",
        "            <filename0>.<ext>\n",
        "            <filename1>.<ext>\n",
        "            ...\n",
        "        labels.json\n",
        "\n",
        "    We convert the json to kili format.\n",
        "    \"\"\"\n",
        "    coco_categories = coco_format[\"categories\"]\n",
        "\n",
        "    import random\n",
        "\n",
        "    number_of_colors = len(coco_categories)\n",
        "\n",
        "    colors = [\n",
        "        \"#\" + \"\".join([random.choice(\"0123456789ABCDEF\") for __ in range(6)])\n",
        "        for _ in range(number_of_colors)\n",
        "    ]\n",
        "\n",
        "\n",
        "    categories = {\n",
        "        camelCase(cat[\"name\"]): {\n",
        "            \"children\": [],\n",
        "            \"name\": cat[\"name\"],\n",
        "            \"color\": color,\n",
        "            \"id\": cat[\"id\"],\n",
        "        }\n",
        "        for cat, color in zip(coco_categories, colors)\n",
        "    }\n",
        "\n",
        "    json_interface = {\n",
        "        \"jobs\": {\n",
        "            job_name: {\n",
        "                \"content\": {\"categories\": categories, \"input\": \"radio\"},\n",
        "                \"instruction\": \"Categories\",\n",
        "                \"isChild\": False,\n",
        "                \"tools\": [\"semantic\"],\n",
        "                \"mlTask\": \"OBJECT_DETECTION\",\n",
        "                \"models\": {\"interactive-segmentation\": {\"job\": job_name + \"_MARKER\"}},\n",
        "                \"isVisible\": True,\n",
        "                \"required\": 1,\n",
        "                \"isNew\": False,\n",
        "            },\n",
        "            job_name + \"_MARKER\": {\n",
        "                \"content\": {\"categories\": categories, \"input\": \"radio\"},\n",
        "                \"instruction\": \"Categories\",\n",
        "                \"isChild\": False,\n",
        "                \"tools\": [\"marker\"],\n",
        "                \"mlTask\": \"OBJECT_DETECTION\",\n",
        "                \"isModel\": True,\n",
        "                \"isVisible\": False,\n",
        "                \"required\": 0,\n",
        "                \"isNew\": False,\n",
        "            },\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return json_interface\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyO3Rhg_g1KL"
      },
      "outputs": [],
      "source": [
        "from kili.client import Kili\n",
        "import json\n",
        "\n",
        "with open(dataset_dir + \"/raw/instances_val2017.json\", \"r\") as f:\n",
        "    coco_format = json.load(f)\n",
        "\n",
        "\n",
        "json_interface = convert_coco_to_kili_json_interface(coco_format=coco_format)\n",
        "\n",
        "assets = [\n",
        "    {\n",
        "        \"externalId\": asset[\"file_name\"],\n",
        "        \"content\": dataset_dir + \"/validation/data/\" + asset[\"file_name\"],\n",
        "        \"metadata\": {},\n",
        "    }\n",
        "    for asset in coco_format[\"images\"][:LIMIT]\n",
        "]\n",
        "\n",
        "\n",
        "kili = Kili(api_endpoint=api_endpoint)\n",
        "\n",
        "# Create project\n",
        "project = kili.create_project(\n",
        "    input_type=\"IMAGE\",\n",
        "    json_interface=json_interface,\n",
        "    title=\"Coco to Kili\",\n",
        "    description=\"\",\n",
        "    project_type=None,\n",
        ")\n",
        "project_id = project[\"id\"] # type:ignore\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqq7EYIYNmkO"
      },
      "source": [
        "#### Add assets and labels to assets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiWx-YdfOAJn"
      },
      "source": [
        "We add labels to half of the data to simulate a project where we haven't labeled much data and we want to predict the labels of the unlabeled data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGxVRBLhNmBG"
      },
      "outputs": [],
      "source": [
        "# Add assets\n",
        "print(f\"Uploading {len(assets)} images to Kili\")\n",
        "external_id_array = [a.get(\"externalId\") for a in assets]\n",
        "content_array = [a.get(\"content\") for a in assets]\n",
        "json_metadata_array = [a.get(\"metadata\") for a in assets]\n",
        "kili.append_many_to_dataset(\n",
        "    project_id=project_id,\n",
        "    content_array=content_array,# type:ignore\n",
        "    external_id_array=external_id_array,# type:ignore\n",
        "    json_metadata_array=json_metadata_array,# type:ignore\n",
        ")\n",
        "\n",
        "\n",
        "# Add labels to half the assets\n",
        "from tqdm import tqdm\n",
        "mapping_external_id_to_semanticjob = convert_coco_to_kili(coco_format=coco_format)\n",
        "asset_ids = kili.assets(project_id=project_id, fields=[\"id\", \"externalId\"], first=int(LIMIT/2))\n",
        "asset_ids = list(asset_ids)\n",
        "print(f\"Labelling {len(asset_ids)} images in Kili\")\n",
        "for i, asset_id in tqdm(enumerate(asset_ids), total=len(asset_ids)):\n",
        "    external_id = asset_id[\"externalId\"]\n",
        "\n",
        "    if external_id in mapping_external_id_to_semanticjob:\n",
        "        semantic_job = mapping_external_id_to_semanticjob[external_id]\n",
        "\n",
        "        # print(f\"Nb annotation on image {external_id}\", len(semantic_job[\"annotations\"]))\n",
        "        kili.append_to_labels(\n",
        "            label_asset_id=asset_id[\"id\"],\n",
        "            json_response={\"SEMANTIC_JOB\": SemanticJob(annotations=semantic_job[\"annotations\"])},\n",
        "        )\n",
        "    else:\n",
        "        print(\"Warning: No Annotation on image\", external_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2WzNF3_Xmy-"
      },
      "outputs": [],
      "source": [
        "# COCO\n",
        "project_id = project_id\n",
        "job_name = \"SEMANTIC_JOB\"\n",
        "\n",
        "# 2 cars (fast demo)\n",
        "# project_id = \"cl4cisaq36awx0lpb8ql57mxk\"\n",
        "# job_name = \"JOB_0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUBHkqXZ37l9"
      },
      "source": [
        "# Training an object detection model with Kiliautoml\n",
        "\n",
        "The following command will automatically download the labeled data in your Kili project. Then, it will choose the right model for Object detection, train it with this data and save it locally. You can visualize the training evolution on Tensorboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKbiXVoq35oL"
      },
      "outputs": [],
      "source": [
        "!rm -rf $KILIAUTOML_CACHE\n",
        "!kiliautoml train --project-id $project_id --epochs 30 --target-job $job_name --api-endpoint $api_endpoint --batch-size 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eW-LsJpatzv8"
      },
      "source": [
        "We just finetuned the model with 100 images for 200 categories. Some categories like scissors have not even been seen by the model. SOTA average precision (AP) is around 60. Here, we trained the model in 7 minutes, but you will need to use more images/raise the number of epochs in production."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQc8p0jiqMva"
      },
      "outputs": [],
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "TENSOR_BOARD=f\"{KILIAUTOML_CACHE}/{project_id}/{job_name}/detectron2/pytorch/model\"\n",
        "%tensorboard --logdir $TENSOR_BOARD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KucbQHbgNQvN"
      },
      "source": [
        "# Preannotate and send predictions\n",
        "\n",
        "\n",
        "Now we can use our local trained model to predict the classes of our text assets and send the prediction scores to the project on Kili. These preannotations can then be validated or corrected by annotators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZFKrfvSCJ2M"
      },
      "outputs": [],
      "source": [
        "!kiliautoml predict --project-id $project_id  --target-job $job_name  --api-endpoint $api_endpoint --max-assets 21000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCW4MLNgPMY4"
      },
      "source": [
        "Now you can ckeck that your assets have predictions on Kili!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJo0nL9YPGj5"
      },
      "outputs": [],
      "source": [
        "print(f\"{KILI_URL}label/projects/{project_id}/menu/queue?currentPage=1&pageSize=20\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9H2R__sfR63p"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "import glob\n",
        "\n",
        "print(f'{KILIAUTOML_CACHE}/{project_id}/{job_name}/detectron2/data/*')\n",
        "\n",
        "files = glob.glob(f'{KILIAUTOML_CACHE}/{project_id}/{job_name}/detectron2/data/*')\n",
        "Image(files[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7NmF6__pzj0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "Demo - Auto ML - Segmentation",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
