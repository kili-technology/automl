# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
# Kili project dataset https://cloud.kili-technology.com/label/projects/ckysuic0y0ldc0lvoeltld164/menu/analytics
# Before running, make sure that the KILI_API_KEY environment variable is set with the API key obtained from Kili
# (in https://cloud.kili-technology.com/label/my-account/api-key if you are using the cloud version)
#
# Example usage: python train.py --data kili.yaml
# parent
# â”œâ”€â”€ yolov5
# â””â”€â”€ datasets
#     â””â”€â”€ kili  â† downloads here
#

# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: {{ data_path }} # ../datasets/kili/<YOUR_KILI_PROJECT_ID> # dataset root dir with your Kili project ID
train: images/train # train images (relative to 'path')
val: images/val # val images (relative to 'path')
test: images/test # test images (optional)

# Classes
names: [{% for class_name in class_names %}"{{ class_name }}", {% endfor %}] # class names, must match your Kili project class names.
nc: {{ number_classes }} # number of classes (cardinality of the list above)

# The proportions of he training and validation dataset, the sum should be < 1.0. The remainder is used as the test set.
train_val_proportions:
  - 0.8
  - 0.1

# Download script/URL (optional)
download: |
  import math
  import os
  import re
  import time
  from kili.client import Kili
  import requests
  from tqdm.auto import tqdm
  print("Downloading datasets from Kili")
  train_val_proportions = yaml['train_val_proportions']
  path = yaml.get('path', '')
  if '/kili/' not in path:
      raise ValueError("'path' field in config must contain '/kili/'")
  project_id = "{{ project_id }}"
  kili = Kili(api_key="{{ kili_api_key }}")
  total ={% if max_assets is not none %} min({{ max_assets }}, kili.count_assets(project_id=project_id)) {% else %} kili.count_assets(project_id=project_id) {% endif %}
  if total == 0:
      raise Exception("No asset in project. Exiting...")
  first = 100
  assets = []
  for skip in tqdm(range(0, total, first)):
      assets += kili.assets(
          project_id=project_id,
          first=first,
          skip=skip,
          disable_tqdm=True,
          fields=[
              'id',
              'content',
              'labels.createdAt',
              'labels.jsonResponse',
              'labels.labelType'])
  assets = [{
          **a,
          'labels': [
              l for l in sorted(a['labels'], key=lambda l: l['createdAt']) \
                  if l['labelType'] in [{% for label_type in label_types %}"{{ label_type }}", {% endfor %}]
          ][-1:],
      } for a in assets]
  assets = [a for a in assets if len(a['labels']) > 0]
  n_train_assets = math.floor(len(assets) * train_val_proportions[0])
  n_val_assets = math.floor(len(assets) * train_val_proportions[1])
  assets_splits = {
      "train": assets[:n_train_assets],
      "val": assets[n_train_assets : n_train_assets + n_val_assets],
      "test": assets[n_train_assets + n_val_assets :],
  }

  for name_split, assets_split in assets_splits.items():
      if len(assets_split) == 0:
          raise Exception("No asset in dataset, exiting...")
      path_split = os.path.join(path, yaml.get(name_split, ''))
      print(f"Building {name_split} in {path_split} ...")
      os.makedirs(path_split, exist_ok=True)
      for asset in tqdm(assets_split):
        img_data = requests.get(asset['content'], headers={
        'Authorization': 'X-API-Key: {{ kili_api_key }}',
        'PROJECT_ID': project_id,
        }).content
        with open(os.path.join(path_split, asset['id'] + '.jpg'), 'wb') as handler:
            handler.write(img_data)


      names = yaml.get('names', [])
      path_labels = re.sub('/images/', '/labels/', path_split)
      print(path_labels)
      os.makedirs(path_labels, exist_ok=True)
      for asset in assets_split:
          with open(os.path.join(path_labels, asset['id'] + '.txt'), 'w') as handler:
              json_response = asset['labels'][0]['jsonResponse']
              for job in json_response.values():
                  for annotation in job.get('annotations', []):
                      name = annotation['categories'][0]['name']
                      try:
                          category = names.index(name)
                      except ValueError:
                          pass
                      bounding_poly = annotation.get('boundingPoly', [])
                      if len(bounding_poly) < 1:
                          continue
                      if 'normalizedVertices' not in bounding_poly[0]:
                          continue
                      normalized_vertices = bounding_poly[0]['normalizedVertices']
                      x_s = [vertice['x'] for vertice in normalized_vertices]
                      y_s = [vertice['y'] for vertice in normalized_vertices]
                      x_min, y_min = min(x_s), min(y_s)
                      x_max, y_max = max(x_s), max(y_s)
                      _x_, _y_ = (x_max + x_min) / 2, (y_max + y_min) / 2
                      _w_, _h_ = x_max - x_min, y_max - y_min
                      handler.write(f'{category} {_x_} {_y_} {_w_} {_h_}\n')
